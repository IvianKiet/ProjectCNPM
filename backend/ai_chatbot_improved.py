"""
Enhanced AI Chatbot Backend for S2O Restaurant System
Uses Google Gemini API with improved context and conversation memory

Key Improvements:
- Rich menu context with categories and pricing details
- Conversation history for contextual responses
- Better error handling and logging
- More detailed restaurant information
- Support for special queries (discounts, recommendations, etc.)
"""

from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional, List, Dict
import uuid
import os
import google.genai as genai
from datetime import datetime
from collections import defaultdict

from database import SessionLocal
from models import Branch, MenuItem, Category, AIConfig, DiningTable

# ============== FastAPI App ==============
app = FastAPI(title="S2O AI Chatbot API - Enhanced", version="2.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============== Gemini API Configuration ==============
GEMINI_API_KEY = "AIzaSyBrYI36zXT9sQXLP5kUkf9mMda57rbQUCM"
client = genai.Client(api_key=GEMINI_API_KEY)

# ============== Conversation Memory ==============
# Store conversation history per branch (in-memory for now)
conversation_history: Dict[str, List[Dict]] = defaultdict(list)
MAX_HISTORY_LENGTH = 10  # Keep last 10 messages for context

# ============== Database Dependency ==============
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ============== Pydantic Schemas ==============
class ChatMessage(BaseModel):
    branch_id: str
    message: str
    session_id: Optional[str] = None  # For conversation tracking

class ChatResponse(BaseModel):
    response: str
    branch_name: str
    session_id: str

class AIConfigResponse(BaseModel):
    config_id: str
    system_prompt: str
    temperature: int

class AIConfigUpdate(BaseModel):
    system_prompt: Optional[str] = None
    temperature: Optional[int] = None

class BranchInfo(BaseModel):
    branch_id: str
    branch_name: str
    address: str
    phone: Optional[str]
    opening_hours: Optional[str]
    closing_hours: Optional[str]

# ============== Helper Functions ==============

def get_rich_branch_context(branch_id: str, db: Session) -> tuple[str, Branch]:
    """
    Build comprehensive branch context with all relevant information
    Returns: (context_string, branch_object)
    """
    try:
        # Get branch info
        branch = db.query(Branch).filter(Branch.branch_id == branch_id).first()
        if not branch:
            raise HTTPException(status_code=404, detail="Branch not found")
        
        print(f"‚úÖ Found branch: {branch.branch_name}")
        print(f"   Branch ID: {branch.branch_id}")
        print(f"   Tenant ID: {branch.tenant_id}")
        
        # Get menu items with categories
        # First, get all categories for this tenant
        tenant_id = branch.tenant_id
        
        # Debug: Check categories
        all_categories = db.query(Category).filter(Category.tenant_id == tenant_id).all()
        print(f"   Found {len(all_categories)} categories for tenant")
        
        # Debug: Check all menu items for this branch (regardless of status)
        all_branch_items = db.query(MenuItem).filter(MenuItem.branch_id == branch_id).all()
        print(f"   Found {len(all_branch_items)} total menu items for branch")
        for item in all_branch_items[:3]:  # Show first 3
            print(f"     - {item.item_name} (status: {item.status}, category: {item.category_id})")
        
        # Query menu items that belong to both this branch AND this tenant's categories
        # Note: Check for both 'active' and 'available' status
        menu_query = db.query(MenuItem, Category).join(
            Category, MenuItem.category_id == Category.category_id
        ).filter(
            MenuItem.branch_id == branch_id,
            Category.tenant_id == tenant_id,
            MenuItem.status.in_(["active", "available"])  # Accept both statuses
        ).order_by(Category.category_name, MenuItem.item_name).all()
        
        print(f"‚úÖ Found {len(menu_query)} active menu items with categories")
        
        # Get dining tables
        tables = db.query(DiningTable).filter(
            DiningTable.branch_id == branch_id
        ).all()
        
        print(f"‚úÖ Found {len(tables)} tables")
        
        # Build comprehensive context
        context = f"""
=== TH√îNG TIN NH√Ä H√ÄNG ===
T√™n: {branch.branch_name}
ƒê·ªãa ch·ªâ: {branch.address or 'Ch∆∞a c·∫≠p nh·∫≠t'}, {branch.province or ''}
S·ªë ƒëi·ªán tho·∫°i: {branch.phone or 'Ch∆∞a c·∫≠p nh·∫≠t'}
Qu·∫£n l√Ω: {branch.manager_name or 'Ch∆∞a c·∫≠p nh·∫≠t'}
Tr·∫°ng th√°i: {'ƒêang ho·∫°t ƒë·ªông' if branch.status == 'active' else 'B·∫£o tr√¨'}

=== GI·ªú M·ªû C·ª¨A ===
Gi·ªù m·ªü c·ª≠a: {branch.opening_hours or 'Ch∆∞a c·∫≠p nh·∫≠t'}
Gi·ªù ƒë√≥ng c·ª≠a: {branch.closing_hours or 'Ch∆∞a c·∫≠p nh·∫≠t'}
Hi·ªán t·∫°i: {datetime.now().strftime('%H:%M')}
{_get_open_status(branch.opening_hours, branch.closing_hours)}

=== TH√îNG TIN THANH TO√ÅN ===
M√£ ng√¢n h√†ng: {branch.bank_code or 'Ch∆∞a c·∫≠p nh·∫≠t'}
S·ªë t√†i kho·∫£n: {branch.bank_account_number or 'Ch∆∞a c·∫≠p nh·∫≠t'}
T√™n t√†i kho·∫£n: {branch.bank_account_name or 'Ch∆∞a c·∫≠p nh·∫≠t'}
Ho√†n ti·ªÅn: {branch.cashback_percent or 0}% cho m·ªçi giao d·ªãch

=== GOOGLE MAPS ===
{branch.google_maps_link or 'Ch∆∞a c√≥ link Google Maps'}

=== TH·ª∞C ƒê∆†N CHI TI·∫æT ===
"""
        
        # Group menu items by category with detailed info
        categories_data = defaultdict(list)
        total_items = 0
        discounted_items = []
        
        for item, category in menu_query:
            total_items += 1
            
            # Calculate price info
            original_price = float(item.price)
            discount = float(item.discount_percent or 0)
            
            item_info = {
                'name': item.item_name,
                'description': item.description or "M√≥n ƒÉn ngon",
                'price': original_price,
                'discount': discount,
                'final_price': original_price * (1 - discount/100) if discount > 0 else original_price,
                'status': item.status
            }
            
            categories_data[category.category_name].append(item_info)
            
            if discount > 0:
                discounted_items.append(item_info)
        
        # Format menu by category
        if categories_data:
            for cat_name, items in sorted(categories_data.items()):
                context += f"\nüìÅ {cat_name} ({len(items)} m√≥n):\n"
                for item in items:
                    price_str = f"{item['final_price']:,.0f}ƒë"
                    if item['discount'] > 0:
                        price_str = f"~{item['final_price']:,.0f}ƒë~ (Gi·∫£m {item['discount']}% t·ª´ {item['price']:,.0f}ƒë)"
                    
                    context += f"  ‚Ä¢ {item['name']}: {price_str}\n"
                    context += f"    M√¥ t·∫£: {item['description']}\n"
        else:
            context += "\nCh∆∞a c√≥ m√≥n ƒÉn n√†o trong th·ª±c ƒë∆°n.\n"
        
        # Add statistics
        context += f"\n=== TH·ªêNG K√ä TH·ª∞C ƒê∆†N ===\n"
        context += f"T·ªïng s·ªë m√≥n: {total_items}\n"
        context += f"S·ªë danh m·ª•c: {len(categories_data)}\n"
        context += f"M√≥n ƒëang gi·∫£m gi√°: {len(discounted_items)}\n"
        
        if discounted_items:
            context += f"\n=== M√ìN ƒêANG GI·∫¢M GI√Å ƒê·∫∂C BI·ªÜT ===\n"
            for item in sorted(discounted_items, key=lambda x: x['discount'], reverse=True):
                context += f"  üî• {item['name']}: Gi·∫£m {item['discount']}% - Ch·ªâ c√≤n {item['final_price']:,.0f}ƒë (t·ª´ {item['price']:,.0f}ƒë)\n"
        
        # Table information
        context += f"\n=== TH√îNG TIN B√ÄN ƒÇN ===\n"
        context += f"T·ªïng s·ªë b√†n: {len(tables)}\n"
        
        available_tables = [t for t in tables if t.status == "available"]
        occupied_tables = [t for t in tables if t.status == "occupied"]
        reserved_tables = [t for t in tables if t.status == "reserved"]
        
        context += f"B√†n tr·ªëng: {len(available_tables)}\n"
        context += f"B√†n ƒëang s·ª≠ d·ª•ng: {len(occupied_tables)}\n"
        context += f"B√†n ƒë√£ ƒë·∫∑t: {len(reserved_tables)}\n"
        
        if available_tables:
            context += f"C√°c b√†n c√≥ th·ªÉ ƒë·∫∑t: {', '.join([t.table_number for t in available_tables[:5]])}\n"
        
        print("‚úÖ Rich context built successfully")
        return context, branch
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error in get_rich_branch_context: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Error building branch context: {str(e)}")


def _get_open_status(opening_hours: str, closing_hours: str) -> str:
    """Determine if restaurant is currently open"""
    if not opening_hours or not closing_hours:
        return "Tr·∫°ng th√°i: Ch∆∞a c·∫≠p nh·∫≠t gi·ªù m·ªü c·ª≠a"
    
    try:
        now = datetime.now()
        current_time = now.strftime("%H:%M")
        
        if opening_hours <= current_time <= closing_hours:
            return "Tr·∫°ng th√°i: üü¢ ƒêANG M·ªû C·ª¨A"
        else:
            return "Tr·∫°ng th√°i: üî¥ ƒêANG ƒê√ìNG C·ª¨A"
    except:
        return "Tr·∫°ng th√°i: Kh√¥ng x√°c ƒë·ªãnh"


def get_ai_config(db: Session) -> tuple:
    """Get AI configuration from database"""
    config = db.query(AIConfig).first()
    
    if not config:
        config = AIConfig(
            config_id=str(uuid.uuid4()),
            system_prompt="""B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh c·ªßa h·ªá th·ªëng nh√† h√†ng S2O. 
Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
- Tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi v·ªÅ nh√† h√†ng m·ªôt c√°ch th√¢n thi·ªán, chuy√™n nghi·ªáp
- Gi·ªõi thi·ªáu m√≥n ƒÉn h·∫•p d·∫´n, g·ª£i √Ω d·ª±a tr√™n s·ªü th√≠ch kh√°ch h√†ng
- Cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ gi·ªù m·ªü c·ª≠a, ƒë·ªãa ch·ªâ, li√™n h·ªá
- H·ªó tr·ª£ kh√°ch h√†ng ƒë·∫∑t b√†n v√† thanh to√°n
- Lu√¥n nhi·ªát t√¨nh, vui v·∫ª v√† h·ªØu √≠ch

Quy t·∫Øc quan tr·ªçng:
- Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p
- N·∫øu kh√¥ng bi·∫øt, h√£y th·ª´a nh·∫≠n m·ªôt c√°ch l·ªãch s·ª±
- Lu√¥n d√πng ti·∫øng Vi·ªát tr·ª´ khi kh√°ch h·ªèi b·∫±ng ti·∫øng Anh
- Gi·ªØ c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß th√¥ng tin
- Th√™m emoji ƒë·ªÉ th√¢n thi·ªán h∆°n (nh∆∞ng ƒë·ª´ng l·∫°m d·ª•ng)""",
            temperature=60
        )
        db.add(config)
        db.commit()
    
    gemini_temperature = config.temperature / 100.0
    return config.system_prompt, gemini_temperature


def add_to_conversation_history(branch_id: str, role: str, content: str):
    """Add message to conversation history"""
    conversation_history[branch_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    
    # Keep only last N messages
    if len(conversation_history[branch_id]) > MAX_HISTORY_LENGTH * 2:
        conversation_history[branch_id] = conversation_history[branch_id][-MAX_HISTORY_LENGTH * 2:]


def get_conversation_context(branch_id: str) -> str:
    """Build conversation history context"""
    history = conversation_history.get(branch_id, [])
    if not history:
        return ""
    
    context = "\n=== L·ªäCH S·ª¨ H·ªòI THO·∫†I G·∫¶N ƒê√ÇY ===\n"
    for msg in history[-6:]:  # Last 3 exchanges
        role_text = "Kh√°ch h√†ng" if msg["role"] == "user" else "B·∫°n"
        context += f"{role_text}: {msg['content']}\n"
    
    return context


# ============== API Endpoints ==============

@app.post("/chat", response_model=ChatResponse)
async def chat_with_ai(chat: ChatMessage, db: Session = Depends(get_db)):
    """
    Enhanced chat endpoint with conversation memory and rich context
    """
    try:
        print(f"\nüîµ New chat request for branch: {chat.branch_id}")
        print(f"üîµ Message: {chat.message}")
        
        # Generate or use session ID
        session_id = chat.session_id or str(uuid.uuid4())
        
        # Get rich branch context
        branch_context, branch = get_rich_branch_context(chat.branch_id, db)
        
        # Get AI configuration
        system_prompt, temperature = get_ai_config(db)
        print(f"‚úÖ AI config loaded. Temperature: {temperature}")
        
        # Get conversation history
        conversation_context = get_conversation_context(chat.branch_id)
        
        # Build full prompt
        full_prompt = f"""{system_prompt}

{branch_context}

{conversation_context}

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- D·ª±a v√†o th√¥ng tin tr√™n ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c
- N·∫øu kh√°ch h·ªèi v·ªÅ m√≥n ƒÉn, h√£y m√¥ t·∫£ chi ti·∫øt v√† n√™u gi√°
- N·∫øu kh√°ch h·ªèi gi·∫£m gi√°, ∆∞u ti√™n gi·ªõi thi·ªáu c√°c m√≥n ƒëang sale
- N·∫øu kh√°ch h·ªèi ƒë∆∞·ªùng, cung c·∫•p ƒë·ªãa ch·ªâ v√† link Google Maps
- N·∫øu kh√°ch h·ªèi gi·ªù m·ªü c·ª≠a, check xem hi·ªán t·∫°i c√≥ m·ªü kh√¥ng
- N·∫øu kh√°ch c·∫ßn ƒë·∫∑t b√†n, h·ªèi th√¥ng tin: s·ªë ng∆∞·ªùi, gi·ªù mu·ªën ƒë·∫øn
- Gi·ªØ c√¢u tr·∫£ l·ªùi s√∫c t√≠ch, th√¢n thi·ªán, d·ªÖ ƒë·ªçc

C√¢u h·ªèi c·ªßa kh√°ch: {chat.message}

Tr·∫£ l·ªùi c·ªßa b·∫°n:"""
        
        print("‚úÖ Calling Gemini API...")
        
        # Generate response
        response = client.models.generate_content(
            model='gemini-2.5-flash',  # Using stable model instead of experimental
            contents=full_prompt,
            config=genai.types.GenerateContentConfig(
                temperature=temperature,
                max_output_tokens=800,
            )
        )
        
        ai_response = response.text
        print(f"‚úÖ Gemini response received: {ai_response[:100]}...")
        
        # Add to conversation history
        add_to_conversation_history(chat.branch_id, "user", chat.message)
        add_to_conversation_history(chat.branch_id, "assistant", ai_response)
        
        return ChatResponse(
            response=ai_response,
            branch_name=branch.branch_name,
            session_id=session_id
        )
        
    except HTTPException as he:
        print(f"‚ùå HTTP Exception: {he.detail}")
        raise
    except Exception as e:
        print(f"‚ùå Unexpected error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"AI Error: {str(e)}"
        )


@app.delete("/chat/history/{branch_id}")
async def clear_conversation_history(branch_id: str):
    """Clear conversation history for a branch"""
    if branch_id in conversation_history:
        del conversation_history[branch_id]
        return {"message": "Conversation history cleared", "branch_id": branch_id}
    return {"message": "No history found", "branch_id": branch_id}


@app.get("/branches/{branch_id}/info", response_model=BranchInfo)
async def get_branch_info(branch_id: str, db: Session = Depends(get_db)):
    """Get basic branch information for the UI"""
    branch = db.query(Branch).filter(Branch.branch_id == branch_id).first()
    if not branch:
        raise HTTPException(status_code=404, detail="Branch not found")
    
    return BranchInfo(
        branch_id=branch.branch_id,
        branch_name=branch.branch_name,
        address=branch.address or "",
        phone=branch.phone,
        opening_hours=branch.opening_hours,
        closing_hours=branch.closing_hours
    )


@app.get("/ai-config", response_model=AIConfigResponse)
async def get_ai_configuration(db: Session = Depends(get_db)):
    """Get current AI configuration"""
    config = db.query(AIConfig).first()
    
    if not config:
        config = AIConfig(
            config_id=str(uuid.uuid4()),
            system_prompt="B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán c·ªßa nh√† h√†ng.",
            temperature=50
        )
        db.add(config)
        db.commit()
    
    return AIConfigResponse(
        config_id=config.config_id,
        system_prompt=config.system_prompt,
        temperature=config.temperature
    )


@app.put("/ai-config")
async def update_ai_configuration(
    config_update: AIConfigUpdate,
    db: Session = Depends(get_db)
):
    """Update AI configuration (Admin only)"""
    config = db.query(AIConfig).first()
    
    if not config:
        raise HTTPException(status_code=404, detail="AI Config not found")
    
    if config_update.system_prompt is not None:
        config.system_prompt = config_update.system_prompt
    
    if config_update.temperature is not None:
        if config_update.temperature < 0 or config_update.temperature > 100:
            raise HTTPException(
                status_code=400,
                detail="Temperature must be between 0 and 100"
            )
        config.temperature = config_update.temperature
    
    db.commit()
    
    return {
        "message": "AI configuration updated successfully",
        "system_prompt": config.system_prompt,
        "temperature": config.temperature
    }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "ok",
        "service": "S2O AI Chatbot Enhanced",
        "version": "2.0.0",
        "active_conversations": len(conversation_history)
    }


# ============== RUN SERVER ==============
if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting S2O AI Chatbot Enhanced Server...")
    print("üìç Server will run on: http://localhost:8001")
    print("üìö API Docs available at: http://localhost:8001/docs")
    print("\nEnhancements:")
    print("  ‚úÖ Rich menu context with categories")
    print("  ‚úÖ Conversation memory")
    print("  ‚úÖ Discount tracking")
    print("  ‚úÖ Table availability")
    print("  ‚úÖ Opening hours check")
    print("\nPress CTRL+C to stop\n")
    
    uvicorn.run(
        "ai_chatbot_improved:app",
        host="0.0.0.0",
        port=8001,
        reload=True
    )